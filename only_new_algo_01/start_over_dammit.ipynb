{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as random\n",
    "import Bio\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import networkx as nx\n",
    "import random as random\n",
    "from tqdm import tqdm # loading bar\n",
    "from utils_copy import linear_C, get_cost_2, get_sequence_string, parse_fasta_multiple, create_score_matrix, write_alignments_to_file, linear_backtrack, fill_graph,new_sp_approxi_combi\n",
    "from utils_copy import convert_to_desired_format_nr_version, compute_cost, my_traversal_simply, extend_alignment_chaos, find_min_span_edges_testing, parse_fasta_multiple_remove_n\n",
    "import timeit\n",
    "from utils_copy import al_integrity_testt\n",
    "from old_for_testing.sp_approx import sp_approx\n",
    "from old_for_testing.utils import *\n",
    "from utils_copy import sum_of_column\n",
    "\n",
    "\n",
    "score_matrix={'a': {'a': 0, 'c': 5, 'g': 2, 't': 5}, 'c': {'a': 5, 'c': 0, 'g': 5, 't': 2}, 'g': {'a': 2, 'c': 5, 'g': 0, 't': 5}, 't': {'a': 5, 'c': 2, 'g': 5, 't': 0}}\n",
    "gap_cost=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_MSA_position_overview_dict(res_matrix):#initializes the overview dictionary\n",
    "    in_which_MSA_is_it={}\n",
    "    names= np.unique(res_matrix[:, 2:])\n",
    "    in_which_MSA_is_it ={name: [int(name),0] for name in names}\n",
    "    print(in_which_MSA_is_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_highest_second_element(d, first_element): #to find the highest col nr already in the MSA\n",
    "    highest_second_element = 0\n",
    "    for key, value in d.items():\n",
    "        if value[0] == first_element:\n",
    "            second_element = value[1]\n",
    "            if second_element > highest_second_element:\n",
    "                highest_second_element = second_element\n",
    "    return highest_second_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_MSA_position_overview_dict(MSA_position_overview_dict,node1,node2): #may be somehow inadequate!\n",
    "    print(node1,node2)\n",
    "    node1_origin_MSA=MSA_position_overview_dict[node1][0]\n",
    "    node2_origin_MSA=MSA_position_overview_dict[node2][0]\n",
    "    node1_origin_MSA_col=MSA_position_overview_dict[node1][1]\n",
    "    node2_origin_col=MSA_position_overview_dict[node2][1]\n",
    "    #now I have the original positions in from the position overview dict!\n",
    "    nr_we_got_to=find_highest_second_element(MSA_position_overview_dict,MSA_position_overview_dict[node1])\n",
    "    MSA_position_overview_dict[node2]=[node1_origin_MSA,(nr_we_got_to+1)] #update the pos_dict to show that node2 changed MSA and make the col one bigger than the max\n",
    "    return MSA_position_overview_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MSA_pos(MSA_position_overview_dict, node):\n",
    "    value=MSA_position_overview_dict[node]\n",
    "    MSA_pos=value[0]\n",
    "    MSA_pos_col=value[1]\n",
    "    return MSA_pos,MSA_pos_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finish_running_through_MSA1(MSA1,MSA2,j,i,l):\n",
    "    how_many_cols_in_MSA2=len(MSA2[0])\n",
    "    gaps_to_add=['-']*how_many_cols_in_MSA2\n",
    "    new_col=list(MSA1[j])+gaps_to_add\n",
    "    return new_col\n",
    "\n",
    "def finish_running_through_MSA2(MSA1,MSA2,j,i,l):\n",
    "    how_many_cols_in_MSA1=len(MSA1[0])\n",
    "    gaps_to_prepend=['-']*how_many_cols_in_MSA1\n",
    "    new_col=gaps_to_prepend+list(MSA2[l])\n",
    "    return new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equality_here_test(a,b):\n",
    "    equality=False\n",
    "    if a=='-' and b=='-' or a!='-' and b!='-':\n",
    "        equality=True\n",
    "    return equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_handle_case1(MSA1,MSA2,i,j,l):\n",
    "    how_many_cols_in_MSA1=len(MSA1[0])\n",
    "    gaps_to_prepend=['-']*how_many_cols_in_MSA1\n",
    "    new_col=gaps_to_prepend+list(MSA2[l])\n",
    "    return new_col #after this, increase only l\n",
    "def alt_handle_case2(MSA1,MSA2,i,j,l):\n",
    "    how_many_cols_in_MSA2=len(MSA2[0])\n",
    "    gaps_to_append=['-']*how_many_cols_in_MSA2\n",
    "    col_now=MSA1[j]\n",
    "    col_new=list(MSA1[j])+gaps_to_append\n",
    "    return col_new #after this, increase only j\n",
    "def alt_handle_case3(MSA1,MSA2,i,j,l):\n",
    "    col_new=list(MSA1[j])+list(MSA2[l])\n",
    "    return col_new #after this, increase i, j and l\n",
    "def alt_handle_case4(MSA1,MSA2,i,j,l):\n",
    "    #col_new=list(MSA1[j])+list(MSA2[l])\n",
    "    how_many_cols_in_MSA1=len(MSA1[0])\n",
    "    how_many_cols_in_MSA2=len(MSA2[0])\n",
    "    #make first column!\n",
    "    first_col_gaps=['-']*how_many_cols_in_MSA2\n",
    "    first_col=list(MSA1[j])+first_col_gaps\n",
    "    #make second colum!\n",
    "    second_col_gaps=['-']*how_many_cols_in_MSA1\n",
    "    second_col=second_col_gaps+list(MSA2[l])\n",
    "    return first_col,second_col #increade l and j after "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_identify_merge_case_compact(guide_PA,MSA1,MSA2,node1,node2,MSA_position_overview_dict,i,j,l):\n",
    "    node1_position=MSA_position_overview_dict[node1]\n",
    "    node1_col=node1_position[1]\n",
    "    node2_position=MSA_position_overview_dict[node2]\n",
    "    node2_col=node2_position[1]\n",
    "    case=None\n",
    "    move_on_in_guide_flag=False\n",
    "    a=guide_PA[i][0]\n",
    "    b=guide_PA[i][1]\n",
    "    c= MSA1[j][node1_col]\n",
    "    d=MSA2[l][node2_col]\n",
    "\n",
    "    if equality_here_test(a,c)==True and equality_here_test(b,d)==True: case=3 #a==c and b==d\n",
    "    elif equality_here_test(a,c)==False and equality_here_test(b,d)==False: case=4\n",
    "        #if equality_here_test(b,c)==True: \n",
    "        #    case=5\n",
    "        #    print(\"WARNING, I ENTERED DAMN CASE 5. PLEASE DEBUG NOW!! a,b,c,d here are set to: \"+str(a)+\" , \"+str(b)+\" ,\"+str(c)+\" , \"+str(d))\n",
    "        #else: \n",
    "        #    case=4 #a!=c and b!=d\n",
    "    elif equality_here_test(a,c)==True:#a==c\n",
    "        if d!='-':\n",
    "            case= 2 #was orginially 1 2 omg just seeing what will happen if I put it to 1. #truing to reverse to see\n",
    "            move_on_in_guide_flag=True\n",
    "        else: case= 1\n",
    "    elif equality_here_test(a,c)==False: #a!=c\n",
    "        if a=='-':\n",
    "            case= 1 #was originally 1 omg!, just checking what will happen if I put it to 2 #reversing to see what will happen...\n",
    "            move_on_in_guide_flag=True\n",
    "        else: case=2\n",
    "    else: sys.exit()\n",
    "    guide_was=guide_PA[i]\n",
    "    MSA2_was=MSA2[l]\n",
    "    return case,move_on_in_guide_flag,guide_was,MSA2_was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_handle_case5(MSA1,MSA2,i,j,l):\n",
    "    how_many_cols_in_MSA1=len(MSA1[0])\n",
    "    how_many_cols_in_MSA2=len(MSA2[0])\n",
    "    #make first column!\n",
    "    first_col_gaps=['-']*how_many_cols_in_MSA2\n",
    "    first_col=list(MSA1[j])+first_col_gaps\n",
    "    #make second colum!\n",
    "    second_col_gaps=['-']*how_many_cols_in_MSA1\n",
    "    second_col=second_col_gaps+list(MSA2[l])\n",
    "    return first_col,second_col #now increase j and l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 True\n"
     ]
    }
   ],
   "source": [
    "move_on_in_guide_flag=False\n",
    "case=False\n",
    "a='a'\n",
    "b='-'\n",
    "c='a'\n",
    "d='t'\n",
    "if equality_here_test(a,c)==True and equality_here_test(b,d)==True: case=3 #a==c and b==d\n",
    "elif equality_here_test(a,c)==False and equality_here_test(b,d)==False:\n",
    "    if equality_here_test(b,c)==True: case=5\n",
    "    else: \n",
    "        case=4 #a!=c and b!=d\n",
    "elif equality_here_test(a,c)==True:#a==c\n",
    "    if d!='-':\n",
    "        case= 2\n",
    "        move_on_in_guide_flag=True\n",
    "    else: case= 1\n",
    "elif equality_here_test(a,c)==False: #a!=c\n",
    "    if a=='-':\n",
    "        case= 1\n",
    "        move_on_in_guide_flag=True\n",
    "    else: case=2\n",
    "else: sys.exit()\n",
    "print (case,move_on_in_guide_flag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_alt_identify_merge_case(guide_PA,MSA1,MSA2,node1,node2,MSA_position_overview_dict,i,j,l):\n",
    "    node1_position=MSA_position_overview_dict[node1]\n",
    "    node1_col=node1_position[1]\n",
    "    node2_position=MSA_position_overview_dict[node2]\n",
    "    node2_col=node2_position[1]\n",
    "    case=None\n",
    "    move_on_in_guide_flag=False\n",
    "    if equality_here_test(guide_PA[i][0],MSA1[j][node1_col])==True and equality_here_test(guide_PA[i][1],MSA2[l][node2_col])==True:\n",
    "        case=3\n",
    "    #elif equality_here_test(guide_PA[i][0],MSA1[j][node1_col])==False and equality_here_test(guide_PA[i][1],MSA2[l][node2_col]==False):\n",
    "    elif equality_here_test(guide_PA[i][0], MSA1[j][node1_col]) == False and equality_here_test(guide_PA[i][1], MSA2[l][node2_col]) == False:\n",
    "        case=4\n",
    "    elif guide_PA[i][0]=='-' and MSA1[j][node1_col]=='-':\n",
    "        case=1\n",
    "        print(str(guide_PA[i][0]),\" , \"+str(guide_PA[i][1])+\" is g1 and g2!\")\n",
    "        if guide_PA[i][0]=='-' and equality_here_test(guide_PA[i][1],MSA1[j][node1_col])==False: #test for flag in case1 new\n",
    "            move_on_in_guide_flag=True\n",
    "    elif guide_PA[i][1]=='-' and MSA2[l][node2_col]=='-':\n",
    "        case=2\n",
    "        print(str(guide_PA[i][0]),\" , \"+str(guide_PA[i][1])+\" is g1 and g2!\")\n",
    "        if guide_PA[i][1]=='-' and equality_here_test(guide_PA[i][1],MSA2[l][node2_col])==False: #test for flag in case2\n",
    "            move_on_in_guide_flag=True\n",
    "    elif guide_PA[i][0]!='-' and MSA1[j][node1_col]!='-' and MSA2[l][node2_col]=='-':\n",
    "        case=1\n",
    "        print(str(guide_PA[i][0]),\" , \"+str(guide_PA[i][1])+\" is g1 and g2!\")\n",
    "        if guide_PA[i][0]=='-' and equality_here_test(guide_PA[i][1],MSA1[j][node1_col])==False: #test for flag in case1 new\n",
    "            move_on_in_guide_flag=True\n",
    "    elif guide_PA[i][0]!='-' and MSA1[j][node1_col]!='-' and guide_PA[i][1]=='-':\n",
    "        case=2\n",
    "        print(str(guide_PA[i][0]),\" , \"+str(guide_PA[i][1])+\" is g1 and g2!\")\n",
    "        if guide_PA[i][1]=='-' and equality_here_test(guide_PA[i][1],MSA2[l][node2_col])==False: #test for flag in case2\n",
    "            move_on_in_guide_flag=True\n",
    "    elif guide_PA[i][1]!='-' and MSA2[l][node2_col]!='-' and guide_PA[i][0]=='-':\n",
    "        case=1\n",
    "        print(str(guide_PA[i][0]),\" , \"+str(guide_PA[i][1])+\" is g1 and g2!\")\n",
    "        if guide_PA[i][0]=='-' and equality_here_test(guide_PA[i][1],MSA1[j][node1_col])==False: #test for flag in case1 new\n",
    "            move_on_in_guide_flag=True\n",
    "    elif guide_PA[i][1]!='-' and MSA2[l][node2_col]!='-' and MSA1[j][node1_col]=='-':\n",
    "        case=2\n",
    "        print(str(guide_PA[i][0]),\" , \"+str(guide_PA[i][1])+\" is g1 and g2!\")\n",
    "        if guide_PA[i][1]=='-' and equality_here_test(guide_PA[i][1],MSA2[l][node2_col])==False: #test for flag in case22\n",
    "            move_on_in_guide_flag=True\n",
    "    else:\n",
    "        sys.exit()\n",
    "    print(\"\\n\\n\")\n",
    "    return case,move_on_in_guide_flag\n",
    "\n",
    "    \n",
    "def alt_alt_merge_united(guide_PA,MSA_list,in_which_MSA_is_it,node1,node2):\n",
    "    print(type(in_which_MSA_is_it))\n",
    "    print(in_which_MSA_is_it)\n",
    "    print(type(node1))\n",
    "    print(type(node2))\n",
    "    MSA_of_node1=in_which_MSA_is_it[node1][0]\n",
    "    MSA_of_node2=in_which_MSA_is_it[node2][0]\n",
    "    spot_of_node1=in_which_MSA_is_it[node1][1]\n",
    "    spot_of_node2=in_which_MSA_is_it[node2][1]\n",
    "    print(MSA_of_node1)\n",
    "    print(MSA_of_node2)\n",
    "    MSA1=MSA_list[int(MSA_of_node1)]\n",
    "    MSA2=MSA_list[int(MSA_of_node2)]\n",
    "    \n",
    "    j=0 \n",
    "    i=0\n",
    "    l=0\n",
    "    MSA_new=[]\n",
    "    while i<=(len(guide_PA)-1) and j<=(len(MSA1)-1) and l<=(len(MSA2)-1):\n",
    "        new_col=[]\n",
    "        print(\"I don't have the case identified yet, but MSA1 is: \" + str(MSA1[j]) + \" MSA2 is: \" + str(MSA2[l]) + \" ,and the guide is: \" + str(guide_PA[i]))\n",
    "        print(\"nodes pointing to cols: \" + str(spot_of_node1) + \" , \" + str(spot_of_node2))\n",
    "        print(\"i,j,l: \"+str(i)+','+str(j)+','+str(l))\n",
    "        print(\"max for those should be: \"+str(len(guide_PA))+','+str(len(MSA1))+','+str(len(MSA2)))\n",
    "        case,move_on_in_guide_flag,guide_was,MSA2_was=new_identify_merge_case_compact(guide_PA,MSA1,MSA2,node1,node2, in_which_MSA_is_it,i,j,l)\n",
    "        print(\"flag: \"+str(move_on_in_guide_flag))\n",
    "        print(\"case:\"+str(case))\n",
    "        print(\"guide_was: \"+str(guide_was))\n",
    "        if case==1:\n",
    "            col=alt_handle_case1(MSA1,MSA2,i,j,l)\n",
    "            MSA_new.append(col) \n",
    "            if move_on_in_guide_flag==True:\n",
    "                print(\"the damn flag was true!\")\n",
    "                i+=1\n",
    "            l+=1\n",
    "            print(\"I just made the new col: \"+ str(col))\n",
    "            print(\"MSA_new now has len: \"+ str(len(MSA_new)))\n",
    "            new_col.append(col)\n",
    "        if case==2:\n",
    "            col=alt_handle_case2(MSA1,MSA2,i,j,l)\n",
    "            MSA_new.append(col)\n",
    "            if move_on_in_guide_flag==True:\n",
    "                print(\"the flag was true dammit\")\n",
    "                i+=1\n",
    "            j+=1\n",
    "            print(\"I just made the new col: \"+ str(col))\n",
    "            print(\"MSA_new now has len: \"+ str(len(MSA_new)))\n",
    "            new_col.append(col)\n",
    "        if case==3:\n",
    "            col=alt_handle_case3(MSA1,MSA2,i,j,l)\n",
    "            MSA_new.append(col)\n",
    "            i+=1\n",
    "            j+=1\n",
    "            l+=1\n",
    "            print(\"I just made the new col: \"+ str(col))\n",
    "            print(\"MSA_new now has len: \"+ str(len(MSA_new)))\n",
    "            new_col.append(col)\n",
    "        if case==4:\n",
    "            col1,col2=alt_handle_case4(MSA1,MSA2,i,j,l)\n",
    "            MSA_new.append(col1)\n",
    "            MSA_new.append(col2)\n",
    "            j+=1\n",
    "            l+=1\n",
    "            print(\"I just made the new col: \"+ str(col1))\n",
    "            print(\"I just made the new col: \"+ str(col2))\n",
    "            print(\"MSA_new now has len: \"+ str(len(MSA_new)))\n",
    "            new_col.append(col1)\n",
    "            new_col.append(col2)\n",
    "        for object in new_col:\n",
    "            print(object)\n",
    "            second_element_in_merged_pair=object[(-(len(MSA2_was))+spot_of_node2)]\n",
    "            selected_stuff=[object[int(spot_of_node1)],second_element_in_merged_pair]\n",
    "            print(\"selected stuff from col made: \")\n",
    "            print(selected_stuff)\n",
    "            if case==1 and move_on_in_guide_flag==False or case==2 and move_on_in_guide_flag==False or case==4:\n",
    "                if guide_was==selected_stuff: print(\"ALERT!\")\n",
    "            if guide_was!=selected_stuff and selected_stuff!=['-', '-']: print(\"ALARM!\")\n",
    "            if case==1 or case==2 and move_on_in_guide_flag==True:\n",
    "                if guide_was!=selected_stuff and selected_stuff!=['-', '-']: print(\"WARNING! i is gonna be increased, maybe unrightfully\")\n",
    "\n",
    "    \n",
    "    print(\"\\n \\n\")\n",
    "        #if case==5:\n",
    "        #    col1,col2=alt_handle_case5(MSA1,MSA2,i,j,l)\n",
    "        #    MSA_new.append(col1)\n",
    "        #    MSA_new.append(col2)\n",
    "        #    l+=1\n",
    "        #    j+=1\n",
    "\n",
    "\n",
    "        #str[col[int(spot_of_node1)],col[int(-(len(col)-spot_of_node2))]]\n",
    "            \n",
    "    if j <= (len(MSA1)-1):\n",
    "        while j<= (len(MSA1)-1):\n",
    "            column=finish_running_through_MSA1(MSA1,MSA2,j,i,l)\n",
    "            j+=1\n",
    "            #l+=1\n",
    "            MSA_new.append(column)\n",
    "            print(\"I just made the new col: \"+ str(column))\n",
    "            print(\"MSA_new now has len: \"+ str(len(MSA_new)))\n",
    "    if l<= (len(MSA2)-1):\n",
    "        while l<= (len(MSA2)-1):\n",
    "            column=finish_running_through_MSA2(MSA1,MSA2,j,i,l)\n",
    "            l+=1\n",
    "            MSA_new.append(column)\n",
    "            print(\"I just made the new col: \"+ str(column))\n",
    "            print(\"MSA_new now has len: \"+ str(len(MSA_new)))\n",
    "    if i<=(len(guide_PA)-1):\n",
    "        print('yikes, the strings have run out but the guide has not')\n",
    "        i+=1\n",
    "    print(\"\\n\\n\")\n",
    "    return MSA_new\n",
    "\n",
    "\n",
    "def alt_alt_the_whole_thing(seqs,score_matrix,gapcost):\n",
    "    # Make a matrix to hold pairwise alignment costs for all alignment combinations!\n",
    "    matrix = np.full((len(seqs), len(seqs)), np.nan)\n",
    "    # Loop over all pairs\n",
    "    for i, seq1 in enumerate(seqs):\n",
    "        for j, seq2 in enumerate(seqs):\n",
    "            matrix[i, j] = get_cost_2(linear_C(gap_cost, score_matrix, seq1, seq2))\n",
    "        print(\"Here comes the distance matrix produced by the alignments: \\n\")\n",
    "        print(matrix)\n",
    "    matrix_for_MST=matrix #copy the matrix, so that we can keep the old matrix and make a changed version to the \"pseudomatrix\" version\n",
    "    matrix_for_MST=convert_to_desired_format_nr_version(matrix_for_MST) #making the \"pseudomatrix\"\n",
    "    print(\"matrix for MST: \"+str(matrix_for_MST))\n",
    "    min_span_edges_res=find_min_span_edges_testing(matrix_for_MST)\n",
    "    print(\"min span edges: \"+str(min_span_edges_res))\n",
    "    in_which_MSA_is_it={}\n",
    "    names= np.unique(min_span_edges_res[:, 2:])\n",
    "    in_which_MSA_is_it ={name: [int(name),0] for name in names}\n",
    "    print(\"this is the positions dict, straight from initialization: \"+str(in_which_MSA_is_it))\n",
    "    #MSA_list=[[*seq] for seq in seqs] #initalizing it as every string in their own alignment with nobody else :) \n",
    "    MSA_list=[[[char] for char in seq] for seq in seqs] #let's try this instead!\n",
    "    print(\"here comes the pos-dict: \"+str(in_which_MSA_is_it))\n",
    "    print(\"look at the current MSA-list: \"+str(MSA_list))\n",
    "    who_aligned_to_who=[]\n",
    "    for row in min_span_edges_res:\n",
    "        if row[0]==\"*\":\n",
    "            #node1 = min(row[2],row[3])  # Extract the first node\n",
    "            node1=row[2]\n",
    "            #node2 = max(row[2],row[3])  # Extract the second node\n",
    "            node2=row[3]\n",
    "            print(\"the nodes for this iteration are: \"+str(node1)+\" and \"+str(node2))\n",
    "            who_aligned_to_who.append([node1,node2])\n",
    "            print(\"these are the sequences I am gonna align initially and then backtrack!\")\n",
    "            print(seqs[int(node1)])\n",
    "            print(seqs[int(node2)])\n",
    "            print(\"this is the whole collection of seqs:\")\n",
    "            print(seqs)\n",
    "            cost=linear_C(gap_cost,score_matrix,seqs[int(node1)],seqs[int(node2)]) #doing the alignment of the two strings :) \n",
    "            alignment1_str,alignment2_str=linear_backtrack(seqs[int(node1)], seqs[int(node2)], cost, score_matrix, gap_cost)\n",
    "            alignment1, alignment2 = [*alignment1_str], [*alignment2_str]\n",
    "            A = [list(e) for e in zip(alignment1,alignment2)]\n",
    "            print(\"original alignment\"+str(A))\n",
    "            orig_str_node2=seqs[int(node2)]\n",
    "            united_MSA_new=alt_alt_merge_united(A,MSA_list,in_which_MSA_is_it,node1,node2)#should bring the merged alignment. Just need to update MSA_list and the dict now then...but also for the others that were joined into it now......\n",
    "            print(\"this is the union produced: \"+ str(united_MSA_new))\n",
    "            print(\"node1 is called: \"+ str(node1))\n",
    "            print(\"node2 is \"+str(node2))\n",
    "            #which_spot_in_MSA_list_to_update=min(in_which_MSA_is_it[node1][0],in_which_MSA_is_it[node2][0])\n",
    "            #which_spot_in_MSA_list_to_remove=max(in_which_MSA_is_it[node1][0],in_which_MSA_is_it[node2][0])\n",
    "            #print(\"spot to update, spot to remove: \"+ str(which_spot_in_MSA_list_to_update)+\" , \"+str(which_spot_in_MSA_list_to_remove))\n",
    "            which_spot_in_MSA_list_to_update=in_which_MSA_is_it[node1][0]\n",
    "            which_spot_in_MSA_list_to_remove=in_which_MSA_is_it[node2][0]\n",
    "            #in_which_MSA_is_it=update_MSA_position_overview_dict(in_which_MSA_is_it,node1,node2)\n",
    "        \n",
    "            \n",
    "            MSA_list[which_spot_in_MSA_list_to_update]=united_MSA_new\n",
    "            MSA_list.pop(which_spot_in_MSA_list_to_remove)\n",
    "            #now to keep track of where everything is, a nightmare..\n",
    "            companions_list=[] #to keep the keys of the strings already in MSA2 for later update.\n",
    "            for key, value in in_which_MSA_is_it.items():\n",
    "                how_many_cols_already_in_MS1=find_highest_second_element(in_which_MSA_is_it,which_spot_in_MSA_list_to_update)\n",
    "                if value[0]>which_spot_in_MSA_list_to_remove:\n",
    "                    value[0]-=1\n",
    "                elif value[0]==which_spot_in_MSA_list_to_remove: #try to avoid updating node2's dict twice hmm! #and key!=str(node2)\n",
    "                    value[0]=which_spot_in_MSA_list_to_update\n",
    "                    companions_list.append(key)\n",
    "            print(\"this is how many cols already in MSA1: \"+str(how_many_cols_already_in_MS1))\n",
    "            print(\"this is the companions list: \"+str(companions_list))\n",
    "            for element in companions_list:\n",
    "                col_of_element_in_old_MSA2=in_which_MSA_is_it[element][1]\n",
    "                print(\"this is column nr of node1 in old MSA2: \"+str(col_of_element_in_old_MSA2))\n",
    "                col_in_new_MSA_node2=int(how_many_cols_already_in_MS1)+int(col_of_element_in_old_MSA2)+1\n",
    "                print(\"new col nr of node2: \"+str(col_in_new_MSA_node2))\n",
    "                print(\"this is the place I try to change: \"+ str(in_which_MSA_is_it[element][1]))\n",
    "                in_which_MSA_is_it[element][1]=col_in_new_MSA_node2\n",
    "                print(\"this is the updated dict: \"+str(in_which_MSA_is_it))\n",
    "                print(\"\\n\\n\")\n",
    "        print(MSA_list)\n",
    "    print(\"here comes the full MSA_list: \")\n",
    "    print(MSA_list)\n",
    "    #integrity check part 1, to check if each string is the same before and after, except for gaps.\n",
    "    for i,seq in enumerate(seqs):\n",
    "        col_to_extract=in_which_MSA_is_it[str(i)][1]\n",
    "        j=0\n",
    "        new_str_with_gaps=[]\n",
    "        new_str_no_gaps=[]\n",
    "        while j<=len(MSA_list[0])-1:\n",
    "            found=MSA_list[0][j][col_to_extract]\n",
    "            j+=1\n",
    "            new_str_with_gaps.append(found)\n",
    "            if found !='-':\n",
    "                new_str_no_gaps.append(found)\n",
    "        new_str_no_gaps=''.join(new_str_no_gaps)\n",
    "        new_str_with_gaps=''.join(new_str_with_gaps)\n",
    "        if new_str_no_gaps==seq:\n",
    "            print(\"integrity check 1 passed for seq \"+str(i))\n",
    "        else:\n",
    "            print(\"Yikes, integrity check 1 did not pas for seq \"+str(i)+\". constrast( new, orig): \\n\"+str(new_str_no_gaps)+\"\\n\"+str(seq))\n",
    "            print(\"here is the whole MSA:\"+ str(MSA_list))\n",
    "    #part 2 lol, are the alignments preserved, expect for gaps???\n",
    "    print(\"structure of who_aligned_to_who: \")\n",
    "    print(who_aligned_to_who)\n",
    "    for element in who_aligned_to_who:\n",
    "        seq1_nr=element[0]\n",
    "        seq2_nr=element[1]\n",
    "        print(\"seq1_nr and seq2_nr are: \"+str(seq1_nr)+\" , \"+str(seq2_nr))\n",
    "        pos_in_MSA_seq1=in_which_MSA_is_it[seq1_nr][1]\n",
    "        pos_in_MSA_seq2=in_which_MSA_is_it[seq2_nr][1]\n",
    "        print(\"pos_in_MSA_seq1,pos_in_MSA_seq2: \"+str(pos_in_MSA_seq1)+\" , \"+str(pos_in_MSA_seq2))\n",
    "        seq1_from_MSA=[]\n",
    "        seq2_from_MSA=[]\n",
    "        j=0\n",
    "        while j<=len(MSA_list[0])-1:\n",
    "            found=MSA_list[0][j][pos_in_MSA_seq1]\n",
    "            seq1_from_MSA.append(found)\n",
    "            j+=1\n",
    "        j=0\n",
    "        while j<=len(MSA_list[0])-1:\n",
    "            found=MSA_list[0][j][pos_in_MSA_seq2]\n",
    "            seq2_from_MSA.append(found)\n",
    "            j+=1\n",
    "        union=[]\n",
    "        k=0\n",
    "        len_max=max(len(seq1_from_MSA),len(seq1_from_MSA))\n",
    "        while k<=(len_max-1):\n",
    "            el1=seq1_from_MSA[k]\n",
    "            el2=seq2_from_MSA[k]\n",
    "            tuple_like_zip=[el1,el2]\n",
    "            union.append(tuple_like_zip)\n",
    "            k+=1\n",
    "        print(\"union of the two after merge looks like: \"+str(union))\n",
    "        cost_after_MSA=compute_cost(union,score_matrix,gap_cost)\n",
    "        if cost_after_MSA==matrix[int(seq1_nr)][int(seq2_nr)]:\n",
    "            print(\"integrity test 2 passed for: \"+str(seq1_nr)+\" and \"+ str(seq2_nr))\n",
    "        else:\n",
    "            print(\"Yikes, integrity check 2 did not pas for: \"+str(seq1_nr)+\" and \"+ str(seq2_nr))\n",
    "            print(\"Costs were before and after:\"+str(matrix[int(node1)][int(node2)])+\" and \"+str(cost_after_MSA))\n",
    "            print(\"look at them:\")\n",
    "            print(union)\n",
    "            print(\"the alignment was supposed to have been:\")\n",
    "            cost=linear_C(gap_cost,score_matrix,seqs[int(seq1_nr)],seqs[int(seq2_nr)]) #doing the alignment of the two strings :) #before I indexed with str1_nr and so on, but lets try this!\n",
    "            print(\"This is the matrix we got from that alignment of the two: \")\n",
    "            print(cost)\n",
    "            print(\"the two int(nodex)'s i'm gonna use for the linear backtrack for comp. are:\"+str(seq1_nr)+\" , \"+str(seq2_nr))\n",
    "            print(\"these are the strings I put into the cost calculation too: \"+str((seqs[int(seq1_nr)],seqs[int(seq2_nr)])))\n",
    "            print(\"these are the two that I use for the bacctrack: \"+str((seqs[int(seq1_nr)], seqs[int(seq2_nr)])))\n",
    "            alignment1_str,alignment2_str=linear_backtrack(seqs[int(seq1_nr)], seqs[int(seq2_nr)],cost, score_matrix, gap_cost)\n",
    "            alignment1, alignment2 = [*alignment1_str], [*alignment2_str]\n",
    "            should_have_been= [list(e) for e in zip(alignment1,alignment2)]\n",
    "            print(\"the alignment was supposed to have been:\")\n",
    "            print(should_have_been)\n",
    "            print(\"after MSA seq if gap cols removed!!: \")\n",
    "            all_gaps_cols_removed_from_union=[sublist for sublist in union if not all(item == '-' for item in sublist)]\n",
    "            print(all_gaps_cols_removed_from_union)\n",
    "            h=0\n",
    "            while h<=len(should_have_been)-1:\n",
    "                if should_have_been[h]==all_gaps_cols_removed_from_union[h]:\n",
    "                    h+=1\n",
    "                else:\n",
    "                    print(\"index of first error: \" + str(h) + \" out of approximately \" + str(len(should_have_been)) + \". The cols are these (should have been, are): \" + str(should_have_been[h]) + \" and \" + str(all_gaps_cols_removed_from_union[h]))\n",
    "                    sys.exit()\n",
    "                    h+=1\n",
    "    total_cost = compute_cost(MSA_list[0], score_matrix, gap_cost)\n",
    "    return(total_cost,MSA_list)\n",
    "\n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_assembly(seqs,score_matrix,gapcost):\n",
    "    # Make a matrix to hold pairwise alignment costs for all alignment combinations!\n",
    "    matrix = np.full((len(seqs), len(seqs)), np.nan)\n",
    "    # Loop over all pairs\n",
    "    for i, seq1 in enumerate(seqs):\n",
    "        for j, seq2 in enumerate(seqs):\n",
    "            matrix[i, j] = get_cost_2(linear_C(gap_cost, score_matrix, seq1, seq2))\n",
    "        print(\"Here comes the distance matrix produced by the alignments: \\n\")\n",
    "        print(matrix)\n",
    "    matrix_for_MST=matrix #copy the matrix, so that we can keep the old matrix and make a changed version to the \"pseudomatrix\" version\n",
    "    matrix_for_MST=convert_to_desired_format_nr_version(matrix_for_MST) #making the \"pseudomatrix\"\n",
    "    print(\"matrix for MST: \"+str(matrix_for_MST))\n",
    "    min_span_edges_res=find_min_span_edges_testing(matrix_for_MST)\n",
    "    print(\"min span edges: \"+str(min_span_edges_res))\n",
    "    in_which_MSA_is_it={}\n",
    "    names= np.unique(min_span_edges_res[:, 2:])\n",
    "    in_which_MSA_is_it ={name: [int(name),0] for name in names}\n",
    "    MSA_list=[[[char] for char in seq] for seq in seqs]\n",
    "    who_aligned_to_who=[]\n",
    "    k=0\n",
    "    for row in min_span_edges_res:\n",
    "        k+=1\n",
    "        if row[0]==\"*\":\n",
    "            node1=row[2]\n",
    "            node2=row[3]\n",
    "            print(\"\\n \\n \\n these are the nodes for the iteration \"+ str(k))\n",
    "            print(node1,node2)\n",
    "            print(\"which correspond to these strings I align: \"+ str(seqs[int(node1)])+\" , \"+str(seqs[int(node1)]) )\n",
    "            who_aligned_to_who.append([node1,node2])\n",
    "            cost=linear_C(gap_cost,score_matrix,seqs[int(node1)],seqs[int(node2)])\n",
    "            alignment1_str,alignment2_str=linear_backtrack(seqs[int(node1)], seqs[int(node2)], cost, score_matrix, gap_cost)\n",
    "            alignment1, alignment2 = [*alignment1_str], [*alignment2_str]\n",
    "            A = [list(e) for e in zip(alignment1,alignment2)]\n",
    "            print(\"original alignment, which is gonna be the guide\"+str(A))\n",
    "            united_MSA_new=alt_alt_merge_united(A,MSA_list,in_which_MSA_is_it,node1,node2)\n",
    "            print(\"here we have the union: \"+str(united_MSA_new))\n",
    "            which_spot_in_MSA_list_to_update=in_which_MSA_is_it[node1][0]\n",
    "            which_spot_in_MSA_list_to_remove=in_which_MSA_is_it[node2][0]\n",
    "            MSA_list[which_spot_in_MSA_list_to_update]=united_MSA_new\n",
    "            MSA_list.pop(which_spot_in_MSA_list_to_remove)\n",
    "            for key, value in in_which_MSA_is_it.items():\n",
    "                how_many_cols_already_in_MS1=find_highest_second_element(in_which_MSA_is_it,which_spot_in_MSA_list_to_update)\n",
    "                companions_to_update=[]\n",
    "                if value[0]==which_spot_in_MSA_list_to_update:\n",
    "                    companions_to_update.append(key)\n",
    "                if value[0]>which_spot_in_MSA_list_to_remove:\n",
    "                    value[0]=(value[0]-1)\n",
    "            for companion in companions_to_update:\n",
    "                col_of_element_in_old_MSA2=in_which_MSA_is_it[companion][1]\n",
    "                in_which_MSA_is_it[companion][1]=(how_many_cols_already_in_MS1+col_of_element_in_old_MSA2+1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return(matrix,min_span_edges_res,in_which_MSA_is_it,MSA_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here comes the distance matrix produced by the alignments: \n",
      "\n",
      "[[ 0. 10.  4. 10.  5.  7.  2.  5.]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]]\n",
      "Here comes the distance matrix produced by the alignments: \n",
      "\n",
      "[[ 0. 10.  4. 10.  5.  7.  2.  5.]\n",
      " [10.  0. 10.  4.  7.  5. 10.  7.]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]]\n",
      "Here comes the distance matrix produced by the alignments: \n",
      "\n",
      "[[ 0. 10.  4. 10.  5.  7.  2.  5.]\n",
      " [10.  0. 10.  4.  7.  5. 10.  7.]\n",
      " [ 4. 10.  0. 10.  7.  5.  2.  7.]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]]\n",
      "Here comes the distance matrix produced by the alignments: \n",
      "\n",
      "[[ 0. 10.  4. 10.  5.  7.  2.  5.]\n",
      " [10.  0. 10.  4.  7.  5. 10.  7.]\n",
      " [ 4. 10.  0. 10.  7.  5.  2.  7.]\n",
      " [10.  4. 10.  0.  5.  7. 10.  5.]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]]\n",
      "Here comes the distance matrix produced by the alignments: \n",
      "\n",
      "[[ 0. 10.  4. 10.  5.  7.  2.  5.]\n",
      " [10.  0. 10.  4.  7.  5. 10.  7.]\n",
      " [ 4. 10.  0. 10.  7.  5.  2.  7.]\n",
      " [10.  4. 10.  0.  5.  7. 10.  5.]\n",
      " [ 5.  7.  7.  5.  0. 10.  7. 10.]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]]\n",
      "Here comes the distance matrix produced by the alignments: \n",
      "\n",
      "[[ 0. 10.  4. 10.  5.  7.  2.  5.]\n",
      " [10.  0. 10.  4.  7.  5. 10.  7.]\n",
      " [ 4. 10.  0. 10.  7.  5.  2.  7.]\n",
      " [10.  4. 10.  0.  5.  7. 10.  5.]\n",
      " [ 5.  7.  7.  5.  0. 10.  7. 10.]\n",
      " [ 7.  5.  5.  7. 10.  0.  7.  4.]\n",
      " [nan nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan nan]]\n",
      "Here comes the distance matrix produced by the alignments: \n",
      "\n",
      "[[ 0. 10.  4. 10.  5.  7.  2.  5.]\n",
      " [10.  0. 10.  4.  7.  5. 10.  7.]\n",
      " [ 4. 10.  0. 10.  7.  5.  2.  7.]\n",
      " [10.  4. 10.  0.  5.  7. 10.  5.]\n",
      " [ 5.  7.  7.  5.  0. 10.  7. 10.]\n",
      " [ 7.  5.  5.  7. 10.  0.  7.  4.]\n",
      " [ 2. 10.  2. 10.  7.  7.  0.  5.]\n",
      " [nan nan nan nan nan nan nan nan]]\n",
      "Here comes the distance matrix produced by the alignments: \n",
      "\n",
      "[[ 0. 10.  4. 10.  5.  7.  2.  5.]\n",
      " [10.  0. 10.  4.  7.  5. 10.  7.]\n",
      " [ 4. 10.  0. 10.  7.  5.  2.  7.]\n",
      " [10.  4. 10.  0.  5.  7. 10.  5.]\n",
      " [ 5.  7.  7.  5.  0. 10.  7. 10.]\n",
      " [ 7.  5.  5.  7. 10.  0.  7.  4.]\n",
      " [ 2. 10.  2. 10.  7.  7.  0.  5.]\n",
      " [ 5.  7.  7.  5. 10.  4.  5.  0.]]\n",
      "matrix for MST: [['' '10' '0' '1']\n",
      " ['' '4' '0' '2']\n",
      " ['' '10' '0' '3']\n",
      " ['' '5' '0' '4']\n",
      " ['' '7' '0' '5']\n",
      " ['' '2' '0' '6']\n",
      " ['' '5' '0' '7']\n",
      " ['' '10' '1' '2']\n",
      " ['' '4' '1' '3']\n",
      " ['' '7' '1' '4']\n",
      " ['' '5' '1' '5']\n",
      " ['' '10' '1' '6']\n",
      " ['' '7' '1' '7']\n",
      " ['' '10' '2' '3']\n",
      " ['' '7' '2' '4']\n",
      " ['' '5' '2' '5']\n",
      " ['' '2' '2' '6']\n",
      " ['' '7' '2' '7']\n",
      " ['' '5' '3' '4']\n",
      " ['' '7' '3' '5']\n",
      " ['' '10' '3' '6']\n",
      " ['' '5' '3' '7']\n",
      " ['' '10' '4' '5']\n",
      " ['' '7' '4' '6']\n",
      " ['' '10' '4' '7']\n",
      " ['' '7' '5' '6']\n",
      " ['' '4' '5' '7']\n",
      " ['' '5' '6' '7']]\n",
      "min span edges: [['*' '2' '0' '6']\n",
      " ['*' '2' '2' '6']\n",
      " ['' '4' '0' '2']\n",
      " ['*' '4' '1' '3']\n",
      " ['*' '4' '5' '7']\n",
      " ['*' '5' '0' '4']\n",
      " ['*' '5' '0' '7']\n",
      " ['*' '5' '1' '5']\n",
      " ['' '5' '2' '5']\n",
      " ['' '5' '3' '4']\n",
      " ['' '5' '3' '7']\n",
      " ['' '5' '6' '7']\n",
      " ['' '7' '0' '5']\n",
      " ['' '7' '1' '4']\n",
      " ['' '7' '1' '7']\n",
      " ['' '7' '2' '4']\n",
      " ['' '7' '2' '7']\n",
      " ['' '7' '3' '5']\n",
      " ['' '7' '4' '6']\n",
      " ['' '7' '5' '6']\n",
      " ['' '10' '0' '1']\n",
      " ['' '10' '0' '3']\n",
      " ['' '10' '1' '2']\n",
      " ['' '10' '1' '6']\n",
      " ['' '10' '2' '3']\n",
      " ['' '10' '3' '6']\n",
      " ['' '10' '4' '5']\n",
      " ['' '10' '4' '7']]\n",
      "these are the nodes for the iteration 1\n",
      "0 6\n",
      "these are the nodes for the iteration 2\n",
      "2 6\n",
      "these are the nodes for the iteration 4\n",
      "1 3\n",
      "these are the nodes for the iteration 5\n",
      "5 7\n",
      "these are the nodes for the iteration 6\n",
      "0 4\n",
      "these are the nodes for the iteration 7\n",
      "0 7\n",
      "these are the nodes for the iteration 8\n",
      "1 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0., 10.,  4., 10.,  5.,  7.,  2.,  5.],\n",
       "        [10.,  0., 10.,  4.,  7.,  5., 10.,  7.],\n",
       "        [ 4., 10.,  0., 10.,  7.,  5.,  2.,  7.],\n",
       "        [10.,  4., 10.,  0.,  5.,  7., 10.,  5.],\n",
       "        [ 5.,  7.,  7.,  5.,  0., 10.,  7., 10.],\n",
       "        [ 7.,  5.,  5.,  7., 10.,  0.,  7.,  4.],\n",
       "        [ 2., 10.,  2., 10.,  7.,  7.,  0.,  5.],\n",
       "        [ 5.,  7.,  7.,  5., 10.,  4.,  5.,  0.]]),\n",
       " array([['*', '2', '0', '6'],\n",
       "        ['*', '2', '2', '6'],\n",
       "        ['', '4', '0', '2'],\n",
       "        ['*', '4', '1', '3'],\n",
       "        ['*', '4', '5', '7'],\n",
       "        ['*', '5', '0', '4'],\n",
       "        ['*', '5', '0', '7'],\n",
       "        ['*', '5', '1', '5'],\n",
       "        ['', '5', '2', '5'],\n",
       "        ['', '5', '3', '4'],\n",
       "        ['', '5', '3', '7'],\n",
       "        ['', '5', '6', '7'],\n",
       "        ['', '7', '0', '5'],\n",
       "        ['', '7', '1', '4'],\n",
       "        ['', '7', '1', '7'],\n",
       "        ['', '7', '2', '4'],\n",
       "        ['', '7', '2', '7'],\n",
       "        ['', '7', '3', '5'],\n",
       "        ['', '7', '4', '6'],\n",
       "        ['', '7', '5', '6'],\n",
       "        ['', '10', '0', '1'],\n",
       "        ['', '10', '0', '3'],\n",
       "        ['', '10', '1', '2'],\n",
       "        ['', '10', '1', '6'],\n",
       "        ['', '10', '2', '3'],\n",
       "        ['', '10', '3', '6'],\n",
       "        ['', '10', '4', '5'],\n",
       "        ['', '10', '4', '7']], dtype='<U21'),\n",
       " {'0': [0, 0],\n",
       "  '1': [1, 0],\n",
       "  '2': [2, 0],\n",
       "  '3': [3, 0],\n",
       "  '4': [4, 0],\n",
       "  '5': [5, 0],\n",
       "  '6': [6, 0],\n",
       "  '7': [7, 0]},\n",
       " [[['a'], ['a']],\n",
       "  [['c'], ['c']],\n",
       "  [['g'], ['g']],\n",
       "  [['t'], ['t']],\n",
       "  [['a'], ['t']],\n",
       "  [['c'], ['g']],\n",
       "  [['g'], ['a']],\n",
       "  [['t'], ['a']]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs_for_small_test=['cgcgc','gtaa','atacg']\n",
    "seqs_for_smallish_test=['cgcgcatcgcttttac','gtaaattctatctct','atacggggggatctatctag','agagatccta','gtgtacactac']\n",
    "tiny_seqs=['aa','cc','gg','tt',\"at\",\"cg\",\"ga\",\"ta\"]\n",
    "brca_seqs_work_please,names=parse_fasta_multiple('brca1-testseqs.fasta')\n",
    "gap_cost=5\n",
    "new_assembly(tiny_seqs,score_matrix,gap_cost)\n",
    "#alt_alt_the_whole_thing(brca_seqs_work_please,score_matrix,gap_cost)\n",
    "#alt_alt_the_whole_thing(seqs_for_small_test,score_matrix,gap_cost)\n",
    "#alt_alt_the_whole_thing(seqs_for_smallish_test,score_matrix,gap_cost)\n",
    "#alt_alt_the_whole_thing(tiny_seqs,score_matrix,gap_cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
